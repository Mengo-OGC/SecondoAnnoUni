\section{Probabilità}

\begin{quotation}
	"Si occupa di prevedere quanto è facile/possibile che qualcosa accada. Consiste in passaggi logici rigorosi partendo da un modello fisso (spazio di probabilità)."
\end{quotation}

\definizione{Fenomeno}{Un fenomeno è qualcosa che acacde e che porta ad'un esito o risultato.}{d:fenomeno}

Un fenomeno può essere:
\begin{itemize}
	\item \textbf{Deterministico} se il risultato può essere predetto con esattezza.
	\item \textbf{Aleatorio} se il risultato è imprevedibile.
\end{itemize}

\definizione{Evento}{Un evento è un insieme di possibili risultati.}{d:evento}

\definizione{Valutazione di probabilità}{La valutazione di probabilità è una funzione che ad'ogni evento associa un numero tanto più grande quanto riteniamo che l'evento possa accadere.}{d:valProb}

\definizione{Evento coerente}{Sia $\Omega$ l'insieme dei risultati. Un evento è un sotto insieme di $\Omega$ di cui ha senso calcolare la valutazione di probabilità, ossia:
\begin{enumerate}
	\item Se $A_1,\dots$ sono eventi allora $\bigcup_i A_i$ è un evento.
	\item Se $A$ è un evento allora $A^C$ è un evento.
	\item $\Omega$ è un evento ($\Omega \in \mathscr{A}$).
\end{enumerate}}{d:eventoProb}

\osservazione{Una collezione di sotto insiemi di $\omega$ che soddisfa tutti i presupposti si dice \textbf{famiglia coerente d'eventi}, con simbolo $\mathscr{A}$.}

\osservazione{Non tutti i sotto insiemi di $\Omega$ sono eventi.}

La valutazione di probabilità, $P$, $P:\mathscr{A}\to\mathbb{R}_{\geqslant0}$, deve soddisfare le proprietà:
\begin{enumerate}
	\item $P(\Omega)=1$.
	\item $P(A)\geqslant0,\forall \ evento \ A$.
	\item Se $A_1,\dots$ sono eventi disgiunti allora \[P(\bigcup_{i=1}^\infty A_i)=\sum_{i=1}^\infty P(A_i)\]
\end{enumerate}

\osservazione{$P$ non ha dominio $\Omega$ ma l'insieme degli eventi. Non calcoliamo la $P$ di un risultato ma di un evento.}

\definizione{Probabilità uniforme}{
La probabilità è uniforme se:
\begin{enumerate}
	\item Se $\Omega$ è finito con $|\Omega|=n$.
	\item Se ogni sotto insieme di $\Omega$ è un evento.
	\item Se $\omega_1$ e $\omega_2$ sono due risultati allora $P(\{\omega_1\})=P(\{\omega_2\})$.
\end{enumerate}

Dalle proprietà della valutazione di probabilità deduciamo anche \[P(\omega_1)+\dots+P(\omega_n)=P(\Omega)=1\]

In generale abbiamo quindi \[P(\omega)=\frac{1}{n}, \forall \omega \in \Omega\]
}{d:probUnif}

\definizione{Probabilità eventi}{Sia $A \in \Omega, A=\{\omega_1,\dots,\omega_k\}$ \[P(A)=\frac{|A|}{|\Omega|}=\frac{\#risultati favorevoli}{\#risultati possibili}\]}{d:probEv}

Ragionamento: $P(A)=P(\omega_1)+\dots+P(\omega_k)=\frac{1}{n}+\dots+\frac{1}{n}=\frac{k}{n}$, se $|A|=k$.

\osservazione{Vale uno spazio con proprietà uniforme.}

\definizione{Non-esempio}{Un non-esempio è qualcosa che non funziona.}{d:nonEsempio}

\mysubsection{Considerazioni elementari}
\begin{itemize}
	\item Se $E$ è un evento allora $E^C$ è un evento.
	\item $E\cup E^C=\Omega$ è un uninoe disguinta.
	\item Se $P(E)+P(E^C)=1$ allora $P(E^C)=1-P(E)$.
\end{itemize}

\osservazione{Il principio di inclusione-esclusione vale anche per l'unione di più di due probabilità.}

\definizione{Probabilità condizionata}{Chiamiamo probabilità condizionata la probabilità che accada l'evento $B$ sapendo che accade l'evento $A$ prima di $B$.\[P(B\mid A)=\frac{P(A\cap B)}{P(A)}\]}{d:probCond}

In altre parole riparametrizziamo la probabilità di $B$ da $\Omega$ al sotto insieme codiviso con $A$.

\osservazione{Ponendo $P'(B)=P(B\mid A)$ allora $P'$ soddisfa le proprietà delle valutazioni di probabilità:
\begin{itemize}
	\item $P'(\Omega)=P(\Omega\mid A)=\frac{P(\Omega \cap A)}{P(A)}=1$.
	\item $P'(A_1\cup A_2)=P'(A_1)+P'(A_2)$ se $A_1,A_2$ sono disgiunti.
\end{itemize}}
\osservazione{$P(A\cap B)=P(B\mid A)P(A)$.}

\definizione{Formula delle probabilità totali}{Sia $\Omega$ partizionato in $\{A_1,A_2,\dots\}$. Per sapere la probabilità d'un evento $B$ condizionato da un qualsiasi altro evento. \[P(B)=\sum_{i=1}^nP(B\cap A_i)=\sum_{i=1}^nP(B\mid A)P(A)\]}{formulaPorblTot}

\definizione{Formula di Bayes}{Siano $A,B$ eventi. \[P(B\mid A)=\frac{P(A\mid B)P(B)}{P(A)}\]}{d:fBaeys}

\dimostrazione{d:fBaeys}{Siano $P(A\mid B)=\frac{P(A\cap B)}{P(B)}$ e $P(B\mid A)=\frac{P(A\cap B)}{P(A)}$. Allora $P(A\cap B)=P(A\mid B)P(B)=P(B\mid A)P(A)=P(A  \cap B)$.}

\definizione{Eventi indipendenti}{$A$ e $B$ sono eventi indipendenti se sapere che accade uno dei due non cambia la probabilità che accada l'altro. \[P(B\mid A)=P(B)\] \[P(A\mid B)=P(A)\]}{d:evDip}

Dato che $P(A\mid B)=\frac{P(A\cap B)}{P(B)}=P(A)$ allora $P(A\cap B)=P(A)P(B)$.

\definizione{Variabili Aleatorie}{Sia $\Omega$ uno spazio di probabilità, $A$ un insieme coerente di eventi e $P$ la valutazione di probabilità.

Una \textbf{variabile aleatoria} è una funzione $X:\Omega\to\mathbb{R}$ tale che $\forall a \in \mathbb{R}, \{\omega\in\Omega\mid X(\omega)\leqslant a\}$, oppure $X\leqslant a$, deve essere un evento. (si scrive anche $\chi_A$).}{d:varAleatoria}

Per una variabile aleatoria non ha senso scrivere $P(X)$, ma ha senso scrivere $P(X\leqslant a)$.
Una variabile aleatoria può essere continua o discreta.

\definizione{Funzione di ripartizione}{Sia $X$ una variabile aleatoria. La sua funzione di ripartizione $F_X$ è una funzione $F_X:\mathbb{R}\to\mathbb{R}$ definita come $F_X(t)=P(X\leqslant t)$.}{d:fRipartizione}

\definizione{Densità concreta discreta}{Sia $X$ una variabile aleatoria discreta.
La densità concreta discreta di $X$ è $dx:\mathbb{R}\to\mathbb{R}$ con \[dx(h)=P(X=h)=
\begin{cases}
	a_1 \ se\ h=0,\dots \\
	\dots \\
	0 \ altrimenti
\end{cases}\] La densità concreta discreta soddisfa le proprietà:
\begin{enumerate}
	\item $dx(h)\geqslant0,\forall h$.
	\item $dx(h)\ne0$ per una quantità finita o numerabile di valori $h$.
	\item $\sum_hdx(h)=1$.
\end{enumerate}}{d:densConc}

\osservazione{Una densità è valida se soddisfa le tre proprietà.}

\definizione{Densità astratta discreta}{Sia $X$ una variabile aleatoria discreta. La densità astratta discreta è $d:\mathbb{R}\to\mathbb{R}$ e soddisfa le proprietà:
\begin{enumerate}
	\item $d(h)\geqslant0,\forall h$.
	\item $d(h)\ne0$ per una quantità discreta di valori $h$.
	\item $\sum_hd(h)=1$.
\end{enumerate}}{d:denAst}

\mysubsection{Approfondimento Serie Geometrica}
Sia $0<a<1$ allora $1-a^n=(1-a)(1+\dots+a^{n-1})$ sapendo che $(1+\dots+a^{n-1}=\frac{1-a^n}{1-a}$ possiamo dire che \[\lim\limits_{h\to\infty}(1+\dots+a^{n-1})=\lim\limits_{h\to\infty}\frac{1-a^n}{1-a}=\frac{1}{1-a}=\sum_{h=0}^\infty a^h\]

\definizione{Densità uniforme}{Sia $X$ una v.a., si dice uniforme nell'insieme $A=\{a_1,\dots,a_n\}\subseteq\mathbb{R}$ se \[dx(h)=
\begin{cases}
	\frac{1}{n} \ se \ h=a_1,\dots,a_n\\
	0 \ altrimenti
\end{cases}\]

Si scrive $X\sim U(\{\dots\})$.}{d:densUnif}

\definizione{Densità di Bernulli}{Si dice densità di Bernulli se $X$ assume solo i valori 0 e 1. \[dx(h)=
\begin{cases}
	p \ se \ h=1\\
	1-p \ se \ h=0\\
	0 \ altrimenti
\end{cases}\]

Si scrive $X\sim B(1,p)$.}{d:densBern}

\osservazione{Si usa quando qualcosa può accadere o non accadere.}

\definizione{Schema successo insuccesso}{Lo schema successo insuccesso è una sequenza di $n$ fenomeni aleatori ognuno dei quali da un successo oppure un insuccesso.}{d:ssi}

\definizione{S.S.I. a prove indipendenti}{Uno schema successo insuccesso si dice a prove indipendenti se:
\begin{enumerate}
	\item Ogni prova ha la stessa probabilità di dare successo.
	\item L'esito di ogni tentativo è indipendente da quello degl'altri.
\end{enumerate}

La variabile $X=\# successi$ la chiamiamo binomiale e scriviamo $X\sim B(h,p)$ con $h$ il numero di tentativi e $p$ la probabilità che ogni tentativo dia successo.

\[dx(k)=
\begin{cases}
	\binom{h}{k}p^k(1-p)^{h-k} \ se \ k=1,\dots,n\\
	0 \ altrimenti
\end{cases}\]}{d:ssiProvInd}

\definizione{S.S.I. senza rimpiazzo}{Sia $\Omega=$ le combinazioni, con probabilità uniforme, di $n$ palline tra blu e rosse, $|\Omega|=\binom{b+r}{n}$.
Uno s.s.i. si dice senza rimpiazzo se:
\begin{enumerate}
	\item L'ordine delle estrazioni non è importate.
	\item Ogni prova non ha la stessa probabilità di dare successo.
	\item L'esito di ogni tentativo non è indipendente da quello degl'altri.
\end{enumerate}

La variabile $X=\# successi$ (estrazione pallina blu) la chiamiamo ipergeometrica. Scriviamo $X\sim H(h,b,r)$ con $h$ il numero di tentativi.

I risultati favorevoli a "$X=k$" sono $\binom{b}{k}\cdot\binom{r}{h-k}$ ossia la scelta di $k$ palline blue per la scelta di $h-k$ palline rosse.

\[P(X=k)=dx(k)=
\begin{cases}
	\frac{\binom{b}{k}\cdot\binom{r}{h-k}}{\binom{b+r}{h}} \ se \ k=0,\dots,n\\
	0 \ altrimenti
\end{cases}\]}{d:ssiSenzaRimpiazzo}

\definizione{Variabili tempo di primo successo}{Sia $\Omega=$ le combinazioni, con probabilità uniforme, di $n$ palline tra blu e rosse, $|\Omega|=\binom{b+r}{n}$.
Si parla di variabile tempo di primo successo quando estraiamo senza rimpiazzo fino ad'ottenere un successo (blu).

Definiamo $T=\#$tentativi effettuati.
Il tempo di primo successo in uno s.s.i. a prove indipendenti definisce:
\begin{enumerate}
	\item $T$=Tempo primo successo che assume $\infty$ valori.
	\item $p$=Probabilità di avere successo ad'ogni tentativo.
\end{enumerate}

\[p(T=k)=(1-p)^{k-1}p\]

\[d_T(k)=
\begin{cases}
	(1-p)^{k-1}p \ se \ k=1,\dots\\
	0 \ altrimenti
\end{cases}\]

Diciamo $T\sim \tilde{G}(p)$, ossia $T$ ha densità geometrica modificata di parametro $p$.
Siccome $d_T$ è una densità abbiamo:

\[\sum_{k=1}^\infty (1-p)^{k-1}p=1\]
}{d:varTempPrimoSucc}

\definizione{Variabili geometrice non modificate}{In uno s.s.i. a prove indipendenti la variabile geometrica $X$ da il numero di fallimenti prima di un successo.

$X+1=T$ è una variabile geometrica modificata con $X$ che assume vlaori da 0 a $+\infty$. Quindi
$dx(k)=P(X=k)=P(T-1=k)=P(T=k+1)=d_T(k+1)=
\begin{cases}
	p(1-p)^k \ se \ k=0,\dots\\
	0 \ altrimenti
\end{cases}$

Scriviamo $X\sim G(p)$.}{d:varGeom}

\proprieta{Mancanza di memoria}{\[P(X\geqslant k+m\mid X\geqslant k)=P(X\geqslant m)\]}{d:mancMem}

\dimostrazione{d:mancMem}{Sia $X\sim G(p)$. Perchè $P(X\geqslant k)$ è uguale a $(1-p)^k$, ossia i primi $k$ tentativi vanno male?
$P(X\geqslant k+m\mid X\geqslant k)=\frac{P(X\geqslant k+m \cap X \geqslant k)}{P(X\geqslant k)}=\frac{(1-p)^{k+m}}{(1-p)^k}=(1-p)^m=P(X\geqslant m)$.}

\definizione{Variabili di Poisson}{Una variabile aleatoria $X$ si dice variabile di Poisson di parametro $\lambda>0$ se ha la seguente densità: \[d(k)=
\begin{cases}
	e^{-\lambda}\frac{\lambda^k}{k!}\ k=0,\dots\\
	0 \ altrimenti
\end{cases}\]

Scriviamo $X\sim P(\lambda)$.}{d:varPoisson}

\osservazione{$d(k)$ è una densità discreta astratta:

\begin{itemize}
	\item $d(k)\geqslant0,\forall k$.
	\item $d(k)\ne0,\forall k \in \mathbb{N}$.
	\item $\sum_{k=0}^\infty d(k)=\sum_{k=0}^\infty e^{-\lambda}\frac{\lambda^k}{k!}=e^{-\lambda}\sum_{k=0}^\infty \frac{\lambda^k}{k!}=e^{-\lambda}e^\lambda=1$.
\end{itemize}}

Ricorda: $e^x=\sum_{k0=}^\infty\frac{x^k}{k!},\forall x \in \mathbb{R}$.

\teorema{Variabile di Poisson}{Sia $X$ una variabile binomiale, $X\sim B(n,p)$, e poniamo $\lambda=pn$ ottentendo $X\sim B(n, \lambda n)$.
Per $n\to\infty$ la densità di $X$ tende alla densità di Poisson $P(\lambda)$.}{t:Poisson}

\dimostrazione{t:Poisson}{La densità di $X$ è

\begin{align*}
	d_x(k) &= \binom{n}{k}\left(\frac{\lambda}{n}\right)^k\left(1-\frac{\lambda}{n}\right)^{n-k}\\
	&= \frac{n(n-1)(n-k+1)}{k!}\frac{\lambda^k}{n^k}\left(1-\frac{\lambda}{n}\right)^n\left(1-\frac{\lambda}{n}\right)^{-k}\\
	&= \underbracket{\frac{\lambda^k}{k!}}_{e^k}\underbracket{\frac{n(n-1)\dots(n-k+1)}{n^k}}_1\underbracket{\left(1-\frac{\lambda}{n}\right)^n}_{e^{-\lambda}}\underbracket{\left(1-\frac{\lambda}{n}\right)^{-k}}_1\\
	&=e^\lambda e^{-\lambda}=1
\end{align*}}

\definizione{Variabili aleatorie multidimensionali}{Una v.a. n-dimensionale è data da $(X_1,\dots,X_n)$ dove $X_1,\dots,X_n$ sono variabili aleatorie.}{d:vam}

\definizione{Variabile aleatoria bidimensionale}{Una variabile aleatoria bidimensionale $(X,Y)$ ha densità $d_{x,y}:\mathbb{R}^2\to\mathbb{R}$.

\[d_{x,y}(h,k)=P(X=h,Y=k)\]}{d:densitàVam2}
La densità multi dimensionale $d_{x,y}$ si dice anche \textbf{densità congiunta}.
La densità delle variabili $X$ e $Y$ , $d_x$ e $d_y$, si dicono \textbf{densità marginali}.
\[
\begin{array}{c|ccc}
	X \backslash Y & 0 & \dots & n\\
	\hline
	0 & n_{00} & \dots & n_{0n}\\
	\vdots & \vdots & \ddots & \vdots\\
	n & n_{n0} & \dots & n_{nn}\\
\end{array}
\begin{array}{cc}
	\\
	=P(X=0)\\
	=P(X=\vdots)\\
	=P(X=n)\\
\end{array}
\]

Le d.marginali sono univocamente determinabili dalla d.congiunta:
\[d_x(h)=\sum_kd_{x,y}(h,k)\]
\[d_y(k)=\sum_hd_{x,y}(h,k)\]

Le densità marginali non determinano la densità congiunta.

\definizione{Variabili aleatorie indipendenti}{Due variabili aleatorie $X,Y$ si dicono indipendenti se

\[P(X=h,Y=k)=P(X=h)P(Y=k)\]

Ossia $d_{x,y}(h,k)=d_x(h)d_y(k), \forall h,k$.}{d:vaIndipendenti}

In altre parole $x$ e $y$ sono indipendenti se gli eventi $"X=h"$ e $"Y=k"$ sono indipendenti per ogni $h,k$.