\section{Probabilità}

\begin{quotation}
	"Si occupa di prevedere quanto è facile/possibile che qualcosa accada. Consiste in passaggi logici rigorosi partendo da un modello fisso (spazio di probabilità)."
\end{quotation}

\definizione{Fenomeno}{Un fenomeno è qualcosa che acacde e che porta ad'un esito o risultato.}{d:fenomeno}

Un fenomeno può essere:
\begin{itemize}
	\item \textbf{Deterministico} se il risultato può essere predetto con esattezza.
	\item \textbf{Aleatorio} se il risultato è imprevedibile.
\end{itemize}

\definizione{Evento}{Un evento è un insieme di possibili risultati.}{d:evento}

\definizione{Valutazione di probabilità}{La valutazione di probabilità è una funzione che ad'ogni evento associa un numero tanto più grande quanto riteniamo che l'evento possa accadere.}{d:valProb}

\definizione{Evento coerente}{Sia $\Omega$ l'insieme dei risultati. Un evento è un sotto insieme di $\Omega$ di cui ha senso calcolare la valutazione di probabilità, ossia:
\begin{enumerate}
	\item Se $A_1,\dots$ sono eventi allora $\bigcup_i A_i$ è un evento.
	\item Se $A$ è un evento allora $A^C$ è un evento.
	\item $\Omega$ è un evento ($\Omega \in \mathscr{A}$).
\end{enumerate}}{d:eventoProb}

\osservazione{Una collezione di sotto insiemi di $\omega$ che soddisfa tutti i presupposti si dice \textbf{famiglia coerente d'eventi}, con simbolo $\mathscr{A}$.}

\osservazione{Non tutti i sotto insiemi di $\Omega$ sono eventi.}

La valutazione di probabilità, $P$, $P:\mathscr{A}\to\mathbb{R}_{\geqslant0}$, deve soddisfare le proprietà:
\begin{enumerate}
	\item $P(\Omega)=1$.
	\item $P(A)\geqslant0,\forall \ evento \ A$.
	\item Se $A_1,\dots$ sono eventi disgiunti allora \[P(\bigcup_{i=1}^\infty A_i)=\sum_{i=1}^\infty P(A_i)\]
\end{enumerate}

\osservazione{$P$ non ha dominio $\Omega$ ma l'insieme degli eventi. Non calcoliamo la $P$ di un risultato ma di un evento.}

\definizione{Probabilità uniforme}{
La probabilità è uniforme se:
\begin{enumerate}
	\item Se $\Omega$ è finito con $|\Omega|=n$.
	\item Se ogni sotto insieme di $\Omega$ è un evento.
	\item Se $\omega_1$ e $\omega_2$ sono due risultati allora $P(\{\omega_1\})=P(\{\omega_2\})$.
\end{enumerate}

Dalle proprietà della valutazione di probabilità deduciamo anche \[P(\omega_1)+\dots+P(\omega_n)=P(\Omega)=1\]

In generale abbiamo quindi \[P(\omega)=\frac{1}{n}, \forall \omega \in \Omega\]
}{d:probUnif}

\definizione{Probabilità eventi}{Sia $A \in \Omega, A=\{\omega_1,\dots,\omega_k\}$ \[P(A)=\frac{|A|}{|\Omega|}=\frac{\#risultati favorevoli}{\#risultati possibili}\]}{d:probEv}

Ragionamento: $P(A)=P(\omega_1)+\dots+P(\omega_k)=\frac{1}{n}+\dots+\frac{1}{n}=\frac{k}{n}$, se $|A|=k$.

\osservazione{Vale uno spazio con proprietà uniforme.}

\definizione{Non-esempio}{Un non-esempio è qualcosa che non funziona.}{d:nonEsempio}

\mysubsection{Considerazioni elementari}
\begin{itemize}
	\item Se $E$ è un evento allora $E^C$ è un evento.
	\item $E\cup E^C=\Omega$ è un uninoe disguinta.
	\item Se $P(E)+P(E^C)=1$ allora $P(E^C)=1-P(E)$.
\end{itemize}

\osservazione{Il principio di inclusione-esclusione vale anche per l'unione di più di due probabilità.}

\definizione{Probabilità condizionata}{Chiamiamo probabilità condizionata la probabilità che accada l'evento $B$ sapendo che accade l'evento $A$ prima di $B$.\[P(B\mid A)=\frac{P(A\cap B)}{P(A)}\]}{d:probCond}

In altre parole riparametrizziamo la probabilità di $B$ da $\Omega$ al sotto insieme codiviso con $A$.

\osservazione{Ponendo $P'(B)=P(B\mid A)$ allora $P'$ soddisfa le proprietà delle valutazioni di probabilità:
\begin{itemize}
	\item $P'(\Omega)=P(\Omega\mid A)=\frac{P(\Omega \cap A)}{P(A)}=1$.
	\item $P'(A_1\cup A_2)=P'(A_1)+P'(A_2)$ se $A_1,A_2$ sono disgiunti.
\end{itemize}}
\osservazione{$P(A\cap B)=P(B\mid A)P(A)$.}

\definizione{Formula delle probabilità totali}{Sia $\Omega$ partizionato in $\{A_1,A_2,\dots\}$. Per sapere la probabilità d'un evento $B$ condizionato da un qualsiasi altro evento. \[P(B)=\sum_{i=1}^nP(B\cap A_i)=\sum_{i=1}^nP(B\mid A)P(A)\]}{formulaPorblTot}

\definizione{Formula di Bayes}{Siano $A,B$ eventi. \[P(B\mid A)=\frac{P(A\mid B)P(B)}{P(A)}\]}{d:fBaeys}

\dimostrazione{d:fBaeys}{Siano $P(A\mid B)=\frac{P(A\cap B)}{P(B)}$ e $P(B\mid A)=\frac{P(A\cap B)}{P(A)}$. Allora $P(A\cap B)=P(A\mid B)P(B)=P(B\mid A)P(A)=P(A  \cap B)$.}

\definizione{Eventi indipendenti}{$A$ e $B$ sono eventi indipendenti se sapere che accade uno dei due non cambia la probabilità che accada l'altro. \[P(B\mid A)=P(B)\] \[P(A\mid B)=P(A)\]}{d:evDip}

Dato che $P(A\mid B)=\frac{P(A\cap B)}{P(B)}=P(A)$ allora $P(A\cap B)=P(A)P(B)$.

\definizione{Variabili Aleatorie}{Sia $\Omega$ uno spazio di probabilità, $A$ un insieme coerente di eventi e $P$ la valutazione di probabilità.

Una \textbf{variabile aleatoria} è una funzione $X:\Omega\to\mathbb{R}$ tale che $\forall a \in \mathbb{R}, \{\omega\in\Omega\mid X(\omega)\leqslant a\}$, oppure $X\leqslant a$, deve essere un evento. (si scrive anche $\chi_A$).}{d:varAleatoria}

Per una variabile aleatoria non ha senso scrivere $P(X)$, ma ha senso scrivere $P(X\leqslant a)$.
Una variabile aleatoria può essere continua o discreta.

\definizione{Funzione di ripartizione}{Sia $X$ una variabile aleatoria. La sua funzione di ripartizione $F_X$ è una funzione $F_X:\mathbb{R}\to\mathbb{R}$ definita come $F_X(t)=P(X\leqslant t)$.}{d:fRipartizione}

\definizione{Densità concreta discreta}{Sia $X$ una variabile aleatoria discreta.
La densità concreta discreta di $X$ è $dx:\mathbb{R}\to\mathbb{R}$ con \[dx(h)=P(X=h)
\begin{cases}
	a_1 \ se\ h=\dots \\
	\dots \\
	0 \ altrimenti
\end{cases}\] La densità concreta discreta soddisfa le proprietà:
\begin{enumerate}
	\item $dx(h)\leqslant0,\forall h$.
	\item $dx(h)\ne0$ per una quantità finita o numerabile di valori $h$.
	\item $\sum_{h=0}^hdx(h)=1$.
\end{enumerate}}{d:densConc}

\osservazione{Una densità è valida se soddisfa le tre proprietà.}

\definizione{Densità astratta discreta}{Sia $X$ una variabile aleatoria discreta. La densità astratta discreta è $d:\mathbb{R}\to\mathbb{R}$. La densità astratta discreta soddisfa le proprietà:
\begin{enumerate}
	\item $d(h)\leqslant0,\forall h$.
	\item $d(h)\ne0$ per una quantità discreta di valori $h$.
	\item $\sum_{h=0}^hd(h)=1$.
\end{enumerate}}{d:denAst}

\mysubsection{Approfondimento Serie Geometrica}
Sia $0<a<1$ allora $1-a^n=(1-a)(1+\dots+a^{n-1})$ sapendo che $(1+\dots+a^{n-1}=\frac{1-a^n}{1-a}$ possiamo dire che \[\lim\limits_{h\to\infty}(1+\dots+a^{n-1})=\lim\limits_{h\to\infty}\frac{1-a^n}{1-a}=\frac{1}{1-a}=\sum_{h=0}^\infty a^h\]

\definizione{Densità uniforme}{Sia $X$ una variabile aleatoria e si dice uniforme nell'insieme $A=\{a_1,\dots,a_n\}\subseteq\mathbb{R}$ se \[dx(h)=
\begin{cases}
	\frac{1}{n} \ se \ h=a_1,\dots,a_n\\
	0 \ altrimenti
\end{cases}\]

Si scrive $X~U(\{\dots\})$.}{d:densUnif}

\definizione{Densità di Bernulli}{Si dice densità di Bernulli se $X$ assume solo i valori 0 e 1. \[dx(h)=
\begin{cases}
	p \ se \ h=1\\
	1-p \ se \ h=0\\
	0 \ altrimenti
\end{cases}\]

Si scrive $X~B(1,p)$}{d:densBern}

\osservazione{Si usa quando qualcosa può accadere o non accadere.}

\definizione{Schema successo insuccesso}{Lo schema successo insuccesso è una sequenza di $n$ fenomeni aleatori ognuno dei quali da un successo oppure un insuccesso.}{d:ssi}

\definizione{S.S.I. a prove indipendenti}{Uno schema successo insuccesso si dice a prove indipendenti se:
\begin{enumerate}
	\item Ogni prova ha la stessa probabilità di dare successo.
	\item L'esito di ogni tentativo è indipendente da quello degl'altri.
\end{enumerate}}{d:ssiProvInd}

La variabile binomiale $X=\# successi$ la chiamiamo binomiale e scriviamo $X~B(h,p)$ con $h$ il numero di tentativi e $p$ la probabilità che ogni tentativo dia successo.

