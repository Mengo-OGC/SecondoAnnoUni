\section{Probabilità}

\begin{quotation}
	"Si occupa di prevedere quanto è facile/possibile che qualcosa accada. Consiste in passaggi logici rigorosi partendo da un modello fisso (spazio di probabilità)."
\end{quotation}

\definizione{Fenomeno}{Un fenomeno è qualcosa che acacde e che porta ad'un esito o risultato.}{d:fenomeno}

Un fenomeno può essere:
\begin{itemize}
	\item \textbf{Deterministico} se il risultato può essere predetto con esattezza.
	\item \textbf{Aleatorio} se il risultato è imprevedibile.
\end{itemize}

\definizione{Evento}{Un evento è un insieme di possibili risultati.}{d:evento}

\definizione{Valutazione di probabilità}{La valutazione di probabilità è una funzione che ad'ogni evento associa un numero tanto più grande quanto riteniamo che l'evento possa accadere.}{d:valProb}

\definizione{Evento coerente}{Sia $\Omega$ l'insieme dei risultati. Un evento è un sotto insieme di $\Omega$ di cui ha senso calcolare la valutazione di probabilità, ossia:
\begin{enumerate}
	\item Se $A_1,\dots$ sono eventi allora $\bigcup_i A_i$ è un evento.
	\item Se $A$ è un evento allora $A^C$ è un evento.
	\item $\Omega$ è un evento ($\Omega \in \mathscr{A}$).
\end{enumerate}}{d:eventoProb}

\osservazione{Una collezione di sotto insiemi di $\omega$ che soddisfa tutti i presupposti si dice \textbf{famiglia coerente d'eventi}, con simbolo $\mathscr{A}$.}

\osservazione{Non tutti i sotto insiemi di $\Omega$ sono eventi.}

La valutazione di probabilità, $P$, $P:\mathscr{A}\to\mathbb{R}_{\geqslant0}$, deve soddisfare le proprietà:
\begin{enumerate}
	\item $P(\Omega)=1$.
	\item $P(A)\geqslant0,\forall \ evento \ A$.
	\item Se $A_1,\dots$ sono eventi disgiunti allora \[P(\bigcup_{i=1}^\infty A_i)=\sum_{i=1}^\infty P(A_i)\]
\end{enumerate}

\osservazione{$P$ non ha dominio $\Omega$ ma l'insieme degli eventi. Non calcoliamo la $P$ di un risultato ma di un evento.}

\definizione{Probabilità uniforme}{
La probabilità è uniforme se:
\begin{enumerate}
	\item Se $\Omega$ è finito con $|\Omega|=n$.
	\item Se ogni sotto insieme di $\Omega$ è un evento.
	\item Se $\omega_1$ e $\omega_2$ sono due risultati allora $P(\{\omega_1\})=P(\{\omega_2\})$.
\end{enumerate}

Dalle proprietà della valutazione di probabilità deduciamo anche \[P(\omega_1)+\dots+P(\omega_n)=P(\Omega)=1\]

In generale abbiamo quindi \[P(\omega)=\frac{1}{n}, \forall \omega \in \Omega\]
}{d:probUnif}

\definizione{Probabilità eventi}{Sia $A \in \Omega, A=\{\omega_1,\dots,\omega_k\}$ \[P(A)=\frac{|A|}{|\Omega|}=\frac{\#risultati favorevoli}{\#risultati possibili}\]}{d:probEv}

Ragionamento: $P(A)=P(\omega_1)+\dots+P(\omega_k)=\frac{1}{n}+\dots+\frac{1}{n}=\frac{k}{n}$, se $|A|=k$.

\osservazione{Vale uno spazio con proprietà uniforme.}

\definizione{Non-esempio}{Un non-esempio è qualcosa che non funziona.}{d:nonEsempio}

\mysubsection{Considerazioni elementari}
\begin{itemize}
	\item Se $E$ è un evento allora $E^C$ è un evento.
	\item $E\cup E^C=\Omega$ è un uninoe disguinta.
	\item Se $P(E)+P(E^C)=1$ allora $P(E^C)=1-P(E)$.
\end{itemize}

\osservazione{Il principio di inclusione-esclusione vale anche per l'unione di più di due probabilità.}

\definizione{Probabilità condizionata}{Chiamiamo probabilità condizionata la probabilità che accada l'evento $B$ sapendo che accade l'evento $A$ prima di $B$.\[P(B\mid A)=\frac{P(A\cap B)}{P(A)}\]}{d:probCond}

In altre parole riparametrizziamo la probabilità di $B$ da $\Omega$ al sotto insieme codiviso con $A$.

\osservazione{Ponendo $P'(B)=P(B\mid A)$ allora $P'$ soddisfa le proprietà delle valutazioni di probabilità:
\begin{itemize}
	\item $P'(\Omega)=P(\Omega\mid A)=\frac{P(\Omega \cap A)}{P(A)}=1$.
	\item $P'(A_1\cup A_2)=P'(A_1)+P'(A_2)$ se $A_1,A_2$ sono disgiunti.
\end{itemize}}
\osservazione{$P(A\cap B)=P(B\mid A)P(A)$.}

\definizione{Formula delle probabilità totali}{Sia $\Omega$ partizionato in $\{A_1,A_2,\dots\}$. Per sapere la probabilità d'un evento $B$ condizionato da un qualsiasi altro evento. \[P(B)=\sum_{i=1}^nP(B\cap A_i)=\sum_{i=1}^nP(B\mid A)P(A)\]}{formulaPorblTot}

\definizione{Formula di Bayes}{Siano $A,B$ eventi. \[P(B\mid A)=\frac{P(A\mid B)P(B)}{P(A)}\]}{d:fBaeys}

\dimostrazione{d:fBaeys}{Siano $P(A\mid B)=\frac{P(A\cap B)}{P(B)}$ e $P(B\mid A)=\frac{P(A\cap B)}{P(A)}$. Allora $P(A\cap B)=P(A\mid B)P(B)=P(B\mid A)P(A)=P(A  \cap B)$.}

\definizione{Eventi indipendenti}{$A$ e $B$ sono eventi indipendenti se sapere che accade uno dei due non cambia la probabilità che accada l'altro. \[P(B\mid A)=P(B)\] \[P(A\mid B)=P(A)\]}{d:evDip}

Dato che $P(A\mid B)=\frac{P(A\cap B)}{P(B)}=P(A)$ allora $P(A\cap B)=P(A)P(B)$.

\definizione{Variabili Aleatorie}{Sia $\Omega$ uno spazio di probabilità, $A$ un insieme coerente di eventi e $P$ la valutazione di probabilità.

Una \textbf{variabile aleatoria} è una funzione $X:\Omega\to\mathbb{R}$ tale che $\forall a \in \mathbb{R}, \{\omega\in\Omega\mid X(\omega)\leqslant a\}$, oppure $X\leqslant a$, deve essere un evento.}{d:varAleatoria}

Per una variabile aleatoria non ha senso scrivere $P(X)$, ma ha senso scrivere $P(X\leqslant a)$.

\definizione{Funzione di ripartizione}{Sia $X$ una variabile aleatoria. La sua funzione di ripartizione $F_X$ è una funzione $F_X:\mathbb{R}\to\mathbb{R}$ definita come $F_X(t)=P(X\leqslant t)$.}{d:fRipartizione}